{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.layers import Input, Convolution2D, BatchNormalization, LeakyReLU, Add, ReLU, GlobalAveragePooling2D, AveragePooling2D, UpSampling2D, Activation \n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 512\n",
    "im_height = 512\n",
    "im_chan = 1\n",
    "\n",
    "path_train = '/kaggle/input/small-dataset/Train/'\n",
    "path_test = '/kaggle/input/small-dataset/Test/'\n",
    "\n",
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=bool)\n",
    "\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    \n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    X_train[n] = x\n",
    "    \n",
    "    \n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    Y_train[n] = mask\n",
    "    \n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(train_ids))\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\n",
    "plt.title(\"Image\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "tmp = np.squeeze(Y_train[ix]).astype(np.float32)\n",
    "plt.imshow(np.dstack((tmp,tmp,tmp)))\n",
    "plt.title(\"Ground truth\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable()\n",
    "class MeanIoUMetric(metrics.Metric):\n",
    "    \n",
    "    def __init__(self, num_classes, name='mean_iou', **kwargs):\n",
    "        super(MeanIoUMetric, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes  # Store num_classes as an attribute\n",
    "        self.iou_metric = metrics.MeanIoU(num_classes=num_classes) \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_ = tf.cast(y_pred > 0.5, tf.int32)  \n",
    "        self.iou_metric.update_state(y_true, y_pred_)\n",
    "\n",
    "    def result(self):\n",
    "        return self.iou_metric.result()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.iou_metric.reset_state()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config) \n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_classes\": self.num_classes})  \n",
    "        return config\n",
    "    \n",
    "    \n",
    "mean_iou_metric = MeanIoUMetric(num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "def simplified_conv_block(X, filters, block, dropout_rate=0.3, l1_reg=1e-6, l2_reg=1e-4):\n",
    "    b = 'block_' + str(block) + '_'\n",
    "    f1, f2 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    \n",
    "    X = Convolution2D(filters=f1, kernel_size=(3, 3), padding='same', name=b + 'a',\n",
    "                      kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(X)\n",
    "    X = BatchNormalization(name=b + 'batch_norm_a')(X)\n",
    "    X = LeakyReLU(alpha=0.2, name=b + 'leakyrelu_a')(X)\n",
    "    X = Dropout(dropout_rate, name=b + 'dropout_a')(X)\n",
    "    \n",
    "    X = Convolution2D(filters=f2, kernel_size=(3, 3), padding='same', name=b + 'b',\n",
    "                      kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(X)\n",
    "    X = BatchNormalization(name=b + 'batch_norm_b')(X)\n",
    "    X = Dropout(dropout_rate, name=b + 'dropout_b')(X)\n",
    "    \n",
    "    X_skip = Convolution2D(filters=f2, kernel_size=(1, 1), padding='same', name=b + 'skip_conv',\n",
    "                           kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(X_skip)\n",
    "    X_skip = BatchNormalization(name=b + 'batch_norm_skip_conv')(X_skip)\n",
    "    \n",
    "    X = Add(name=b + 'add')([X, X_skip])\n",
    "    X = ReLU(name=b + 'relu')(X)\n",
    "    return X\n",
    "\n",
    "def simplified_base_feature_maps(input_layer, dropout_rate=0.3, l1_reg=1e-6, l2_reg=1e-4):\n",
    "    \n",
    "    base = simplified_conv_block(input_layer, [32, 64], '1', dropout_rate, l1_reg, l2_reg)\n",
    "    base = simplified_conv_block(base, [64, 128], '2', dropout_rate, l1_reg, l2_reg)\n",
    "    return base\n",
    "\n",
    "def simplified_pyramid_feature_maps(input_layer, dropout_rate=0.3, l1_reg=1e-6, l2_reg=1e-4):\n",
    "    base = simplified_base_feature_maps(input_layer, dropout_rate, l1_reg, l2_reg)\n",
    "    \n",
    "   \n",
    "    yellow = AveragePooling2D(pool_size=(2, 2), name='yellow_pool')(base)\n",
    "    yellow = Convolution2D(filters=32, kernel_size=(1, 1), name='yellow_1_by_1',\n",
    "                           kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(yellow)\n",
    "    yellow = Dropout(dropout_rate, name='yellow_dropout')(yellow)\n",
    "    yellow = UpSampling2D(size=(2, 2), interpolation='bilinear', name='yellow_upsampling')(yellow)\n",
    "    \n",
    "    blue = AveragePooling2D(pool_size=(4, 4), name='blue_pool')(base)\n",
    "    blue = Convolution2D(filters=32, kernel_size=(1, 1), name='blue_1_by_1',\n",
    "                         kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(blue)\n",
    "    blue = Dropout(dropout_rate, name='blue_dropout')(blue)\n",
    "    blue = UpSampling2D(size=(4, 4), interpolation='bilinear', name='blue_upsampling')(blue)\n",
    "    \n",
    "    return tf.keras.layers.concatenate([base, yellow, blue])\n",
    "\n",
    "def simplified_last_conv_module(input_layer, dropout_rate=0.3, l1_reg=1e-6, l2_reg=1e-4):\n",
    "    X = simplified_pyramid_feature_maps(input_layer, dropout_rate, l1_reg, l2_reg)\n",
    "    X = Convolution2D(filters=1, kernel_size=(3, 3), padding='same', name='last_conv_3_by_3',\n",
    "                      kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(X)\n",
    "    X = BatchNormalization(name='last_conv_3_by_3_batch_norm')(X)\n",
    "    X = Dropout(dropout_rate, name='last_conv_dropout')(X)\n",
    "    X = Activation('sigmoid', name='last_conv_sigmoid')(X)\n",
    "    return X\n",
    "\n",
    "input_layer = Input(shape=(im_height, im_width, im_chan))\n",
    "output_layer = simplified_last_conv_module(input_layer)\n",
    "simplified_pspnet_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "simplified_pspnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou_metric])\n",
    "simplified_pspnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=10, verbose=2)\n",
    "checkpointer = ModelCheckpoint('PSPNET.keras', verbose=1, save_best_only=True)\n",
    "results = pspnet_model.fit(X_train, Y_train, validation_split=0.2, batch_size=2, epochs=150,\n",
    "                           callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = {\n",
    "    \"training_loss\": \"#0072B2\",  # Blue\n",
    "    \"validation_loss\": \"#D55E00\",  # Red\n",
    "    \"training_iou\": \"#009E73\",  # Green\n",
    "    \"validation_iou\": \"#CC79A7\"  # Purple\n",
    "}\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "\n",
    "ax1.plot(results.history['loss'], label='Training Loss', color=colors[\"training_loss\"], linewidth=2)\n",
    "ax1.plot(results.history['val_loss'], label='Validation Loss', color=colors[\"validation_loss\"], linewidth=2, linestyle='--')\n",
    "ax1.set_xlabel('Epochs', fontsize=14)\n",
    "ax1.set_ylabel('Loss', fontsize=14, color=colors[\"training_loss\"])\n",
    "ax1.tick_params(axis='y', labelcolor=colors[\"training_loss\"])\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(results.history['mean_iou'], label='Training Mean IoU', color=colors[\"training_iou\"], linewidth=2)\n",
    "ax2.plot(results.history['val_mean_iou'], label='Validation Mean IoU', color=colors[\"validation_iou\"], linewidth=2, linestyle='--')\n",
    "ax2.set_ylabel('Mean IoU', fontsize=14, color=colors[\"training_iou\"])\n",
    "ax2.tick_params(axis='y', labelcolor=colors[\"training_iou\"])\n",
    "\n",
    "ax1.grid(False)  \n",
    "ax2.grid(False)\n",
    "\n",
    "\n",
    "plt.title('Training and Validation Metrics', fontsize=16)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "plt.legend(lines + lines2, labels + labels2, loc='lower left', ncol=2, fontsize=12) \n",
    "\n",
    "ax1.set_ylim(0, 1) \n",
    "\n",
    "plt.savefig('PSP_Net.png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize test images and masks\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_ids), im_height, im_width, 1), dtype=bool) \n",
    "\n",
    "\n",
    "\n",
    "print('Getting and resizing test images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    X_test[n] = x\n",
    "\n",
    "\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    Y_test[n] = mask\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    '/kaggle/working/PSPNET.keras',\n",
    "    custom_objects={'MeanIoUMetric': MeanIoUMetric} ,safe_mode=False\n",
    ")\n",
    "\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1, batch_size=2)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a sanity check on some random Test Samples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    " \n",
    "plt.style.use('seaborn-whitegrid') \n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))  \n",
    "fig.subplots_adjust(hspace=0.3, wspace=-0.5)\n",
    "\n",
    "for i in range(3):\n",
    "    if i ==0 :\n",
    "        axes[i, 0].set_title(\"Image\", fontsize=16) \n",
    "        axes[i, 1].set_title(\"Ground Truth\", fontsize=16)\n",
    "        axes[i, 2].set_title(\"Predicted\", fontsize=16)\n",
    "        \n",
    "        \n",
    "    ix = random.randint(0, len(preds_test_t) - 1) \n",
    "\n",
    "    # Image\n",
    "    axes[i, 0].imshow(np.dstack((X_test[ix], X_test[ix], X_test[ix])))\n",
    "    \n",
    "    axes[i, 0].axis('off') \n",
    "\n",
    "    \n",
    "    # Ground Truth\n",
    "    im_gt = axes[i, 1].imshow(Y_test[ix], cmap='inferno')\n",
    "    \n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "\n",
    "    \n",
    "    # Prediction\n",
    "    im_pred = axes[i, 2].imshow(preds_test_t[ix], cmap='inferno')\n",
    "    \n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "\n",
    "plt.savefig(\"prediction_visualization.png\", dpi=600) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
