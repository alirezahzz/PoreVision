{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img \n",
    "from tensorflow import image as tf_image\n",
    "from tensorflow import data as tf_data\n",
    "from tensorflow import io as tf_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = 512\n",
    "im_height = 512\n",
    "im_chan = 1\n",
    "path_train = '/kaggle/input/small-dataset/Train/'\n",
    "path_test = '/kaggle/input/small-dataset/Test/'\n",
    "\n",
    "train_ids = next(os.walk(path_train+\"images\"))[2]\n",
    "test_ids = next(os.walk(path_test+\"images\"))[2]\n",
    "print(len(train_ids))\n",
    "print(len(test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(train_ids), im_height, im_width, 3), dtype=np.uint8) \n",
    "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = resize(x, (512, 512, 1), mode='constant', preserve_range=True)\n",
    "    x = np.stack((x[:, :, 0], x[:, :, 0], x[:, :, 0]), axis=2) \n",
    "    X_train[n] = x\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    Y_train[n] = resize(mask, (512, 512, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "@register_keras_serializable()\n",
    "class MeanIoUMetric(metrics.Metric):\n",
    "    def __init__(self, num_classes, name='mean_iou', **kwargs):\n",
    "        super(MeanIoUMetric, self).__init__(name=name, **kwargs)\n",
    "        self.num_classes = num_classes \n",
    "        self.iou_metric = metrics.MeanIoU(num_classes=num_classes) \n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred_ = tf.cast(y_pred > 0.5, tf.int32) \n",
    "        self.iou_metric.update_state(y_true, y_pred_)\n",
    "\n",
    "    def result(self):\n",
    "        return self.iou_metric.result()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.iou_metric.reset_state()\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)  \n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_classes\": self.num_classes}) \n",
    "        return config\n",
    "    \n",
    "mean_iou_metric = MeanIoUMetric(num_classes=2)\n",
    "\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "def convolution_block(\n",
    "    block_input,\n",
    "    num_filters=128,\n",
    "    kernel_size=3,\n",
    "    dilation_rate=1,\n",
    "    use_bias=False,\n",
    "    dropout_rate=0.2,\n",
    "    l1_reg=1e-6,\n",
    "    l2_reg=1e-4,\n",
    "):\n",
    "    x = layers.Conv2D(\n",
    "        num_filters,\n",
    "        kernel_size=kernel_size,\n",
    "        dilation_rate=dilation_rate,\n",
    "        padding=\"same\",\n",
    "        use_bias=use_bias,\n",
    "        kernel_initializer=keras.initializers.HeNormal(),\n",
    "        kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)\n",
    "    )(block_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = ops.nn.relu(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n",
    "def DilatedSpatialPyramidPooling(dspp_input, image_size, dropout_rate=0.2, l1_reg=1e-6, l2_reg=1e-4):\n",
    "    dims = dspp_input.shape\n",
    "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
    "    x = convolution_block(x, num_filters=64, kernel_size=1, use_bias=True, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    \n",
    "    out_pool = layers.UpSampling2D(\n",
    "        size=(dims[-3], dims[-2]), \n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    \n",
    "    out_1 = convolution_block(dspp_input, num_filters=64, kernel_size=1, dilation_rate=1, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    out_6 = convolution_block(dspp_input, num_filters=64, kernel_size=3, dilation_rate=6, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    out_12 = convolution_block(dspp_input, num_filters=64, kernel_size=3, dilation_rate=12, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12])\n",
    "    output = convolution_block(x, num_filters=128, kernel_size=1, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    return output\n",
    "\n",
    "def DeeplabV3Plus(image_size, num_classes, dropout_rate=0.2, l1_reg=1e-6, l2_reg=1e-4):\n",
    "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
    "    preprocessed = keras.applications.resnet50.preprocess_input(model_input)\n",
    "    resnet50 = keras.applications.ResNet50(\n",
    "        weights=\"imagenet\", include_top=False, input_tensor=preprocessed\n",
    "    )\n",
    "    \n",
    "    x = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "    x = DilatedSpatialPyramidPooling(x, image_size, dropout_rate, l1_reg, l2_reg)\n",
    "    \n",
    "    input_a = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]), \n",
    "        interpolation=\"bilinear\",\n",
    "    )(x)\n",
    "    \n",
    "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
    "    input_b = convolution_block(input_b, num_filters=32, kernel_size=1, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    \n",
    "    input_b = layers.UpSampling2D(\n",
    "        size=(input_a.shape[1] // input_b.shape[1], input_a.shape[2] // input_b.shape[2]),\n",
    "        interpolation=\"bilinear\"\n",
    "    )(input_b)\n",
    "    \n",
    "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
    "    \n",
    "    x = convolution_block(x, num_filters=64, dropout_rate=dropout_rate, l1_reg=l1_reg, l2_reg=l2_reg)\n",
    "    \n",
    "    x = layers.UpSampling2D(\n",
    "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
    "        interpolation=\"bilinear\"\n",
    "    )(x)\n",
    "    \n",
    "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", \n",
    "                                 kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg))(x)\n",
    "    return keras.Model(inputs=model_input, outputs=model_output)\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "NUM_CLASSES = 1\n",
    "DROPOUT_RATE = 0.3\n",
    "L1_REG = 1e-6\n",
    "L2_REG = 1e-4\n",
    "\n",
    "model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES, \n",
    "                      dropout_rate=DROPOUT_RATE, l1_reg=L1_REG, l2_reg=L2_REG)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=[mean_iou_metric])\n",
    "earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "checkpointer = ModelCheckpoint('Deeplabv3plus.keras', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=8, epochs=150,callbacks=[earlystopper,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-ticks')  \n",
    "plt.figure(figsize=(14, 7))  \n",
    "\n",
    "plt.plot(results.history['loss'], label='Training Loss', linestyle='-', linewidth=2, color='#3498db')\n",
    "plt.plot(results.history['mean_iou'], label='Mean IoU', linestyle='-', linewidth=2, color='#2ecc71')\n",
    "plt.plot(results.history['val_mean_iou'], label='Validation Mean IoU', linestyle='--', linewidth=2, color='#f39c12')\n",
    "\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=14)\n",
    "plt.ylabel('Loss / Mean IoU', fontsize=14)  \n",
    "plt.title('Training and Validation Metrics', fontsize=16)\n",
    "\n",
    "\n",
    "plt.legend(fontsize=12, loc='lower left') \n",
    "\n",
    "\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.savefig('DeeplabV3+.png', dpi=600)  \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize test images and masks\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_test = np.zeros((len(test_ids), im_height, im_width, 1), dtype=bool) \n",
    "\n",
    "\n",
    "\n",
    "print('Getting and resizing test images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = path_test\n",
    "    img = load_img(path + '/images/' + id_)\n",
    "    x = img_to_array(img)[:,:,1]\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    X_test[n] = x\n",
    "\n",
    "\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n",
    "    mask = np.expand_dims(mask, axis=-1)\n",
    "    Y_test[n] = mask\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    '/kaggle/working/Deeplabv3plus.keras',\n",
    "    custom_objects={'MeanIoUMetric': MeanIoUMetric} ,safe_mode=False\n",
    ")\n",
    "\n",
    "\n",
    "preds_test = model.predict(X_test, verbose=1)\n",
    "preds_test_t = (preds_test > 0.2).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform a sanity check on some random Test Samples\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    " \n",
    "plt.style.use('seaborn-whitegrid') \n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))  \n",
    "fig.subplots_adjust(hspace=0.3, wspace=-0.5)\n",
    "\n",
    "for i in range(3):\n",
    "    if i ==0 :\n",
    "        axes[i, 0].set_title(\"Image\", fontsize=16) \n",
    "        axes[i, 1].set_title(\"Ground Truth\", fontsize=16)\n",
    "        axes[i, 2].set_title(\"Predicted\", fontsize=16)\n",
    "        \n",
    "        \n",
    "    ix = random.randint(0, len(preds_test_t) - 1) \n",
    "\n",
    "    # Image\n",
    "    axes[i, 0].imshow(X_test[ix])\n",
    "    \n",
    "    axes[i, 0].axis('off') \n",
    "\n",
    "    \n",
    "    # Ground Truth\n",
    "    im_gt = axes[i, 1].imshow(Y_test[ix], cmap='inferno')\n",
    "    \n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "\n",
    "    \n",
    "    # Prediction\n",
    "    im_pred = axes[i, 2].imshow(preds_test_t[ix], cmap='inferno')\n",
    "    \n",
    "    axes[i, 2].axis('off')\n",
    "    \n",
    "\n",
    "plt.savefig(\"prediction_visualization.png\", dpi=600) \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
